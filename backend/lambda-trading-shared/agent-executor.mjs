// Lambda Trading Shared Module: Agent Executor
// ç”¨é€”ï¼šç»Ÿä¸€çš„ LLM Agent æ‰§è¡Œæ¡†æ¶ï¼Œé…ç½®é©±åŠ¨ï¼Œæ¶ˆé™¤é‡å¤ä»£ç 
// ç‰¹ç‚¹ï¼šé›†ä¸­ç®¡ç†æ‰€æœ‰ Agent é…ç½®ï¼Œç»Ÿä¸€è°ƒç”¨æµç¨‹

import {
    callOpenAI,
    callGemini,
    callClaude,
    callGrok,
    callDeepSeekBedrock,
    callQwen3Bedrock
} from './llm-clients.mjs';
import { parseAndValidateDecision } from './decision-parser.mjs';

// ============================================
// Agent é…ç½®é›†ä¸­ç®¡ç†
// ============================================

/**
 * æ‰€æœ‰ LLM Agent çš„é…ç½®
 * æ¯ä¸ª agent åŒ…å«ï¼š
 * - llmClient: LLM å®¢æˆ·ç«¯å‡½æ•°ï¼ˆæ¥è‡ª llm-clients.mjsï¼‰
 * - llmOptions: LLM è°ƒç”¨é€‰é¡¹ï¼ˆmodel, temperature, maxTokens ç­‰ï¼‰
 * - displayName: ç”¨äºæ—¥å¿—æ˜¾ç¤ºçš„åç§°
 */
export const AGENT_CONFIGS = {
    // OpenAI (2ä¸ª)
    openai_standard: {
        llmClient: callOpenAI,
        llmOptions: {
            model: 'gpt-4.1',
            temperature: 0.7,
            maxTokens: 2000,
            timeout: 120000,
            maxRetries: 2
        },
        displayName: 'GPT-4.1'
    },
    openai_mini: {
        llmClient: callOpenAI,
        llmOptions: {
            model: 'gpt-4o-mini',
            temperature: 0.7,
            maxTokens: 2000,
            timeout: 60000,
            maxRetries: 1
        },
        displayName: 'GPT-4o mini'
    },

    // Gemini (2ä¸ª) - é€šè¿‡ gptsapi.net ä»£ç†ï¼Œä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
    gemini_pro: {
        llmClient: callOpenAI,  // gptsapi.net ä½¿ç”¨ OpenAI æ ¼å¼
        llmOptions: {
            baseURL: 'https://api.gptsapi.net/v1',
            model: 'gemini-2.5-pro',
            temperature: 0.7,
            maxTokens: 8000,
            timeout: 120000,
            maxRetries: 1
        },
        displayName: 'Gemini 2.5 Pro'
    },
    gemini_flash: {
        llmClient: callOpenAI,  // gptsapi.net ä½¿ç”¨ OpenAI æ ¼å¼
        llmOptions: {
            baseURL: 'https://api.gptsapi.net/v1',
            model: 'gemini-2.5-flash',
            temperature: 0.7,
            maxTokens: 8000,
            timeout: 60000,
            maxRetries: 1
        },
        displayName: 'Gemini 2.5 Flash'
    },

    // Claude (2ä¸ª) - é€šè¿‡ gptsapi.net ä»£ç†
    claude_standard: {
        llmClient: callClaude,
        llmOptions: {
            baseURL: 'https://api.gptsapi.net/v1',
            model: 'claude-sonnet-4-5-20250929',
            temperature: 0.7,
            maxTokens: 2000,
            timeout: 120000,
            maxRetries: 2
        },
        displayName: 'Sonnet 4.5'
    },
    claude_mini: {
        llmClient: callClaude,
        llmOptions: {
            baseURL: 'https://api.gptsapi.net/v1',
            model: 'claude-haiku-4-5-20251001',
            temperature: 0.7,
            maxTokens: 2000,
            timeout: 60000,
            maxRetries: 1
        },
        displayName: 'Haiku 4.5'
    },

    // Grok (2ä¸ª)
    grok_standard: {
        llmClient: callGrok,
        llmOptions: {
            model: 'grok-4-fast-reasoning',
            temperature: 0.7,
            maxTokens: 2000,
            timeout: 120000,
            maxRetries: 2
        },
        displayName: 'Grok 4 Fast Reasoning'
    },
    grok_mini: {
        llmClient: callGrok,
        llmOptions: {
            model: 'grok-4-fast-non-reasoning',
            temperature: 0.7,
            maxTokens: 2000,
            timeout: 60000,
            maxRetries: 1
        },
        displayName: 'Grok 4 Fast'
    },

    // DeepSeek (1ä¸ª) - AWS Bedrock
    deepseek: {
        llmClient: callDeepSeekBedrock,
        llmOptions: {
            model: 'deepseek.v3-v1:0',
            temperature: 0.7,
            maxTokens: 4000,
            timeout: 300000
        },
        displayName: 'DeepSeek'
    },

    // Qwen (1ä¸ª) - AWS Bedrock
    qwen3_235b: {
        llmClient: callQwen3Bedrock,
        llmOptions: {
            model: 'qwen.qwen3-235b-a22b-2507-v1:0',
            temperature: 0.7,
            maxTokens: 4000,
            timeout: 300000
        },
        displayName: 'Qwen3 235B'
    }
};

// ============================================
// ç»Ÿä¸€çš„ Agent æ‰§è¡Œå‡½æ•°
// ============================================

/**
 * æ‰§è¡Œ LLM Agent å†³ç­–
 *
 * @param {string} agentName - Agent åç§°ï¼ˆå¦‚ 'openai_standard', 'claude_mini'ï¼‰
 * @param {Function} promptBuilder - Prompt æ„å»ºå‡½æ•°ï¼ˆè¿”å› stringï¼‰
 * @param {Object} apiKeys - API Key æ˜ å°„å¯¹è±¡ { agentName: apiKey }
 * @returns {Promise<{decision: Object, usage: Object|null}>}
 *
 * @example
 * const { decision, usage } = await executeAgent(
 *     'openai_standard',
 *     () => buildTradingPrompt(marketData, portfolio),
 *     { openai_standard: process.env.OPENAI_API_KEY }
 * );
 */
export async function executeAgent(agentName, promptBuilder, apiKeys) {
    // 1. è·å– Agent é…ç½®
    const config = AGENT_CONFIGS[agentName];
    if (!config) {
        throw new Error(`Unknown agent: ${agentName}`);
    }

    const { llmClient, llmOptions, displayName } = config;

    try {
        // 2. æ„å»º Promptï¼ˆç”± Lambda æä¾›ï¼Œä¸šåŠ¡é€»è¾‘ï¼‰
        const prompt = promptBuilder();

        // 3. è°ƒç”¨ LLMï¼ˆæ·»åŠ  API Keyï¼‰
        const apiKey = apiKeys[agentName];
        const options = { ...llmOptions, apiKey };

        const result = await llmClient(prompt, options);

        // 4. è®°å½• Token ä½¿ç”¨é‡
        if (result.usage) {
            console.log(`ğŸ“Š ${displayName} Token Usage:`, result.usage);
        }

        // 5. è§£æå†³ç­–
        const decision = parseAndValidateDecision(result.text, displayName);

        return {
            decision,
            usage: result.usage
        };

    } catch (error) {
        console.error(`[${displayName}] API call failed:`, error);

        // é”™è¯¯ fallbackï¼šè¿”å› HOLD å†³ç­–
        const errorMsg = error?.message || String(error) || 'æœªçŸ¥é”™è¯¯';
        return {
            decision: {
                action: 'hold',
                asset: null,
                amount: 0,
                reason: `APIè°ƒç”¨å¤±è´¥ï¼ˆ${errorMsg}ï¼‰ï¼Œä¿æŒæŒæœ‰`
            },
            usage: null
        };
    }
}

// ============================================
// å·¥å…·å‡½æ•°ï¼šè·å– Agent çš„æ˜¾ç¤ºåç§°
// ============================================

/**
 * è·å– Agent çš„æ˜¾ç¤ºåç§°
 * @param {string} agentName - Agent åç§°
 * @returns {string} æ˜¾ç¤ºåç§°
 */
export function getAgentDisplayName(agentName) {
    const config = AGENT_CONFIGS[agentName];
    return config ? config.displayName : agentName;
}

// ============================================
// å·¥å…·å‡½æ•°ï¼šè·å–æ‰€æœ‰å¯ç”¨ Agent åç§°
// ============================================

/**
 * è·å–æ‰€æœ‰é…ç½®çš„ Agent åç§°åˆ—è¡¨
 * @returns {string[]} Agent åç§°æ•°ç»„
 */
export function getAllAgentNames() {
    return Object.keys(AGENT_CONFIGS);
}

// ============================================
// å·¥å…·å‡½æ•°ï¼šéªŒè¯ Agent æ˜¯å¦å­˜åœ¨
// ============================================

/**
 * æ£€æŸ¥ Agent æ˜¯å¦å­˜åœ¨äºé…ç½®ä¸­
 * @param {string} agentName - Agent åç§°
 * @returns {boolean}
 */
export function isValidAgent(agentName) {
    return agentName in AGENT_CONFIGS;
}
